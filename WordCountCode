#Import necessary libraries
import re
import matplotlib.pyplot as plt
from more_itertools import locate

#Special Function for splitting matches by spaces and filtering out \n and special characters(?,!)
def filterList(x):
    result = []

    for i in x:
        for k in i.split(" "):
            k = re.sub('[!.?,]', '', k)
            k = re.sub("\n","", k)
            if(k != "" and k != "\n"):
                result.append(k)
    
    return result

#Special function for counting the number of occurences for each word in all dialogues
def filterWordSet(results):
    newWordSet = {}
    
    for word in results:
        matches  = list(locate(results, lambda x: x == word))
    
        if word not in newWordSet:
            newWordSet[word] = len(matches)
            
    return newWordSet

            
#Open text file (read only) and store it inside a variable 
txt = open("starwars.txt", "r")
file_contents = txt.read()

#Apply changes for tokenizer
file_contents = file_contents.lower()
file_contents = file_contents.replace("\n\n","|")

#Find all matches for all important characters using regex string
lukeResults = re.findall(r"(?<=\bluke\b)([\w\n]+[\w' !?\n.,-]+)", file_contents)
vaderResults = re.findall(r"(?<=\bvader\b)([\w\n]+[\w' !?\n.,-]+)", file_contents)
benResults = re.findall(r"(?<=\bben\b)([\w\n]+[\w' !?\n.,-]+)", file_contents)
leiaResults = re.findall(r"(?<=\bleia\b)([\w\n]+[\w' !?\n.,-]+)", file_contents)
hanResults = re.findall(r"(?<=\bhan\b)([\w\n]+[\w' !?\n.,-]+)", file_contents)

#Combine all dialogue into one list
wordSet = filterList(list(lukeResults)) + filterList(list(vaderResults)) + filterList(list(benResults)) + filterList(list(leiaResults)) + filterList(list(hanResults))

#Sort list in order
sortedwordSet = sorted(filterWordSet(wordSet).items(),key=lambda x: x[1], reverse=True)
        
#Print sorted list
for x in sortedwordSet:
    print(x[0], " = " , x[1])
